<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[typora-vue-theme主题介绍]]></title>
    <url>%2F2019%2F01%2F17%2Ftypora-vue-theme-zhu-ti-jie-shao%2F</url>
    <content type="text"><![CDATA[English Document | 演示示例 | QQ交流群:926552981 这是一个采用Material Design和响应式设计的 Hexo 博客主题。 特性 简单漂亮，文章内容美观易读 Material Design设计 响应式设计，博客在桌面端、平板、手机等设备上均能很好的展现 每天动态切换Banner图片 瀑布流式的博客文章列表(文章无特色图片时会有24张漂亮的图片代替) 时间轴式的归档页 词云的标签页和雷达图的分类页 丰富的关于我页面（包括关于我、文章统计图、我的项目、我的技能、相册等） 可自定义的数据的友情链接页面 支持文章置顶和文章打赏 支持MathJax TOC目录 可设置复制文章内容时追加版权信息 可设置阅读文章时做密码验证 Gitalk、Gitment、Valine和Disqus评论模块（推荐使用Gitalk） 集成了不蒜子统计和谷歌分析(Google Analytics) 后续开发计划 重构标签页为可分页 重构归档页为可分页 增加分类页 增加关于我页面 阅读文章验证密码 集成Gitalk 右上角实现fork me on github 添加RSS 添加文章TOC 网站底部加上访问量等统计功能（主题使用者可以基于谷歌分析、百度统计、LeanCloud等来实现） 首页设计和添加置顶文章 文章结束后增加打赏功能 为博客添加萌萌的宠物或者成长树等（可以使用hexo-helper-live2d插件来实现） 集成Valine 增加阅读文章验证密码的功能 增加了对MathJax的支持 制作一个LOGO 增加友情链接页面 添加复制文章内容时追加博客版权信息 添加点击页面的’爱心’效果 欢迎贡献! 下载当你看到这里的时候，应该已经有一个自己的Hexo博客了，如果还没有的话，不妨使用 Hexo 和Markdown来写博客和文章。 点击 这里 下载master分支的最新稳定版的代码，解压缩后，将hexo-theme-matery的文件夹复制到你 Hexo 的themes文件夹中即可。当然你也可以在你的themes文件夹下使用Git clone命令来下载: git clone https://github.com/blinkfox/hexo-theme-matery.git 配置切换主题修改 Hexo 根目录下的_config.yml的theme的值：theme: hexo-theme-matery _config.yml文件的其它修改建议: 请修改_config.yml的url的值为你的网站主URL（如：http://xxx.github.io）。 建议修改两个per_page的分页条数值为6的倍数，如：12、18等，这样文章列表在各个屏幕下都能较好的显示。 如果你是中文用户，则建议修改language的值为zh-CN。 新建分类 categories 页categories页是用来展示所有分类的页面，如果在你的博客source目录下还没有categories/index.md文件，那么你就需要新建一个，命令如下： hexo new page "categories" 编辑你刚刚新建的页面文件/source/categories/index.md，至少需要以下内容： --- title: categories date: 2018-09-30 17:25:30 type: "categories" layout: "categories" --- 新建标签 tags 页tags页是用来展示所有标签的页面，如果在你的博客source目录下还没有tags/index.md文件，那么你就需要新建一个，命令如下： hexo new page "tags" 编辑你刚刚新建的页面文件/source/tags/index.md，至少需要以下内容： --- title: tags date: 2018-09-30 18:23:38 type: "tags" layout: "tags" --- 新建关于我 about 页about页是用来展示关于我和我的博客信息的页面，如果在你的博客source目录下还没有about/index.md文件，那么你就需要新建一个，命令如下： hexo new page "about" 编辑你刚刚新建的页面文件/source/about/index.md，至少需要以下内容： --- title: about date: 2018-09-30 17:25:30 type: "about" layout: "about" --- 新建友情连接 friends 页（可选的）friends页是用来展示友情连接信息的页面，如果在你的博客source目录下还没有friends/index.md文件，那么你就需要新建一个，命令如下： hexo new page "friends" 编辑你刚刚新建的页面文件/source/friends/index.md，至少需要以下内容： --- title: friends date: 2018-12-12 21:25:30 type: "friends" layout: "friends" --- 同时，在你的博客source目录下新建_data目录，在_data目录中新建friends.json文件，文件内容如下所示： [{ "avatar": "http://image.luokangyuan.com/1_qq_27922023.jpg", "name": "码酱", "introduction": "我不是大佬，只是在追寻大佬的脚步", "url": "http://luokangyuan.com/", "title": "前去学习" }, { "avatar": "http://image.luokangyuan.com/4027734.jpeg", "name": "闪烁之狐", "introduction": "编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬", "url": "https://blinkfox.github.io/", "title": "前去学习" }, { "avatar": "http://image.luokangyuan.com/avatar.jpg", "name": "ja_rome", "introduction": "平凡的脚步也可以走出伟大的行程", "url": "ttps://me.csdn.net/jlh912008548", "title": "前去学习" }] 代码高亮由于 Hexo 自带的代码高亮主题显示不好看，所以主题中使用到了hexo-prism-plugin的 Hexo 插件来做代码高亮，安装命令如下： npm i -S hexo-prism-plugin 然后，修改 Hexo 根目录下_config.yml文件中highlight.enable的值为false，并新增prism插件相关的配置，主要配置如下： highlight: enable: false prism_plugin: mode: 'preprocess' # realtime/preprocess theme: 'tomorrow' line_number: false # default false custom_css: 搜索本主题中还使用到了hexo-generator-search的 Hexo 插件来做内容搜索，安装命令如下： npm install hexo-generator-search --save 在 Hexo 根目录下的_config.yml文件中，新增以下的配置项： search: path: search.xml field: post 中文链接转拼音（可选的）如果你的文章名称是中文的，那么 Hexo 默认生成的永久链接也会有中文，这样不利于SEO，且gitment评论对中文链接也不支持。我们可以用hexo-permalink-pinyin Hexo 插件使在生成文章时生成中文拼音的永久链接。 安装命令如下： npm i hexo-permalink-pinyin --save 在 Hexo 根目录下的_config.yml文件中，新增以下的配置项： permalink_pinyin: enable: true separator: '-' # default: '-' 注：除了此插件外，hexo-abbrlink插件也可以生成非中文的链接。 添加RSS订阅支持（可选的）本主题中还使用到了hexo-generator-feed的 Hexo 插件来做RSS，安装命令如下： npm install hexo-generator-feed --save 在 Hexo 根目录下的_config.yml文件中，新增以下的配置项： feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' ' order_by: -date 执行 hexo clean &amp;&amp; hexo g重新生成博客文件，然后在public文件夹中即可看到atom.xml文件，说明你已经安装成功了。 修改页脚页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的/layout/_partial/footer.ejs文件中，包括站点、使用的主题、访问量等。 修改社交链接在主题文件的/layout/_partial/social-link.ejs文件中，你可以修改或添加你需要的社交链接地址，增加链接可参考如下代码： &lt;a href="https://github.com/blinkfox" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"> &lt;i class="fa fa-github">&lt;/i> &lt;/a> 其中，社交图标（如：fa-github）你可以在Font Awesome中搜索找到。以下是常用社交图标的标识，供你参考： Facebook: fa-facebook Twitter: fa-twitter Google-plus: fa-google-plus Linkedin: fa-linkedin Tumblr: fa-tumblr Medium: fa-medium Slack: fa-slack 新浪微博: fa-weibo 微信: fa-wechat QQ: fa-qq 注意: 本主题中使用的Font Awesome版本为4.5.0。 修改打赏的二维码图片在主题文件的source/medias/reward文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。 文章Front-matter示例以下为文章Front-matter的示例，所有内容均为非必填的。但是，仍然建议至少填写title的值，当然最好都填写上这些文章信息。 --- title: typora-vue-theme主题介绍 date: 2018-09-07 09:25:00 author: 赵奇 img: /source/images/xxx.jpg # 或者:http://xxx.com/xxx.jpg top: true # 如果top值为true，则会是首页推荐文章 # 如果要对文章设置阅读验证密码的话，就可以在设置password的值，该值必须是用SHA256加密后的密码，防止被他人识破 password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92 # 本文章是否开启mathjax，且需要在主题的_config.yml文件中也需要开启才行 mathjax: false categories: Markdown tags: - Typora - Markdown --- 注意: 如果img属性不填写的话，文章特色图会根据文章标题的hashcode的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图各有特色。 date的值尽量保证每篇文章是唯一的，因为本主题中Gitalk和Gitment识别id是通过date的值来作为唯一标识的。 如果要对文章设置阅读验证密码的功能，不仅要在Front-matter中设置采用了SHA256加密的password的值，还需要在主题的_config.yml中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：开源中国在线工具、chahuo、站长工具。 效果截图 自定制修改在本主题的_config.yml中可以修改部分自定义信息，有以下几个部分： 菜单 首页的励志名言 是否显示推荐文章名称和按钮配置 favicon 和 Logo 个人信息 TOC目录 文章打赏信息 复制文章内容时追加版权信息 MathJax 点击页面的’爱心’效果 我的项目 我的技能 我的相册 Gitalk、Gitment、Valine和disqus评论配置 不蒜子统计和谷歌分析(Google Analytics) 默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的hashcode值取余，来选择展示对应的特色图 我认为个人博客应该都有自己的风格和特色。如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的_config.yml中完成，需要修改源代码才来完成。以下列出了可能对你有用的地方： 修改主题颜色在主题文件的/source/css/matery.css文件中，搜索.bg-color来修改背景颜色： /* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */ .bg-color { background-image: linear-gradient(to right, #4cbf30 0%, #0f9d58 100%); } /* 和背景颜色相同的文字颜色，目前仅在首页一个地方使用到，你也可以将此样式应用到其他地方. */ .text-color { color: #0f9d58 !important; } @-webkit-keyframes rainbow { /* 动态切换背景颜色. */ } @keyframes rainbow { /* 动态切换背景颜色. */ } 修改banner图和文章特色图你可以直接在/source/medias/banner文件夹中更换你喜欢的banner图片，主题代码中是每天动态切换一张，只需7张即可。如果你会JavaScript代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，banner切换的代码位置在/layout/_partial/bg-cover.ejs文件的&lt;script&gt;&lt;/script&gt;代码中： $('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)'); 在/source/medias/featureimages文件夹中默认有24张特色图片，你可以再增加或者减少，并需要在_config.yml做同步修改。]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Typora</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F17%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new "My New Post" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java 8 中的 Streams API 详解]]></title>
    <url>%2F2018%2F02%2F12%2Fjava-8-zhong-de-streams-api-xiang-jie%2F</url>
    <content type="text"><![CDATA[为什么需要 StreamStream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream是完全不同的概念。它也不同于 StAX 对 XML 解析的 Stream，也不是 Amazon Kinesis 对大数据实时处理的 Stream。Java8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregateoperation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的 java.util.stream是一个函数式语言+多核时代综合影响的产物。 什么是聚合操作在传统的 J2EE 应用中，Java 代码经常不得不依赖于关系型数据库的聚合操作来完成诸如： 客户每月平均消费金额 最昂贵的在售商品 本周完成的有效订单（排除了无效的） 取十个数据样本作为首页推荐 这类的操作。 但在当今这个数据大爆炸的时代，在数据来源多样化、数据海量化的今天，很多时候不得不脱离 RDBMS，或者以底层返回的数据为基础进行更上层的数据统计。而Java 的集合 API 中，仅仅有极少量的辅助型方法，更多的时候是程序员需要用 Iterator来遍历集合，完成相关的聚合应用逻辑。这是一种远不够高效、笨拙的方法。在 Java 7 中，如果要发现 type 为 grocery的所有交易，然后返回以交易值降序排序好的交易 ID 集合，我们需要这样写： 清单 1. Java 7 的排序、取值实现List &lt; Transaction > groceryTransactions = new Arraylist &lt; > (); for (Transaction t: transactions) { if (t.getType() == Transaction.GROCERY) { groceryTransactions.add(t); } } Collections.sort(groceryTransactions, new Comparator() { public int compare(Transaction t1, Transaction t2) { return t2.getValue().compareTo(t1.getValue()); } }); List &lt; Integer > transactionIds = new ArrayList &lt; > (); for (Transaction t: groceryTransactions) { transactionsIds.add(t.getId()); } 而在 Java 8 使用 Stream，代码更加简洁易读；而且使用并发模式，程序执行速度更快。 清单 2. Java 8 的排序、取值实现List &lt; Integer > transactionsIds = transactions.parallelStream(). filter(t - > t.getType() == Transaction.GROCERY). sorted(comparing(Transaction::getValue).reversed()). map(Transaction::getId). collect(toList()); Stream 总览什么是流Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如“过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。 Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。 而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程基本如下： 1.0-1.4 中的 java.lang.Thread 5.0 中的 java.util.concurrent 6.0 中的 Phasers 等 7.0 中的 Fork/Join 框架 8.0 中的 Lambda Stream 的另外一大特点是，数据源本身可以是无限的。 流的构成当我们使用一个流的时候，通常包括三个基本步骤： 获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。 图 1. 流管道 (Stream Pipeline) 的构成 点击查看大图 有多种方式生成 Stream Source： 从 Collection 和数组 Collection.stream() Collection.parallelStream() Arrays.stream(T array) or Stream.of()从 BufferedReader java.io.BufferedReader.lines() 静态工厂 java.util.stream.IntStream.range() java.nio.file.Files.walk() 自己构建 java.util.Spliterator其它 Random.ints() BitSet.stream() Pattern.splitAsStream(java.lang.CharSequence) JarFile.stream() 流的操作类型分为两种： Intermediate ：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。 Terminal ：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。 在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream对应的集合，然后对每个元素执行所有的函数。 还有一种操作被称为 short-circuiting 。用以指： 对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。 对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。 当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。 清单 3. 一个流操作的示例int sum = widgets.stream() .filter(w - > w.getColor() == RED) .mapToInt(w - > w.getWeight()) .sum(); stream() 获取当前小物件的 source，filter 和 mapToInt 为 intermediate 操作，进行数据筛选和转换，最后一个sum() 为 terminal 操作，对符合条件的全部小物件作重量求和。 流的使用详解简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。 流的构造与转换下面提供最常见的几种构造 Stream 的样例。 清单 4. 构造流的几种常见方法// 1. Individual values Stream stream = Stream.of("a", "b", "c"); // 2. Arrays String[] strArray = new String[] { "a", "b", "c" }; stream = Stream.of(strArray); stream = Arrays.stream(strArray); // 3. Collections List &lt; String > list = Arrays.asList(strArray); stream = list.stream(); 需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream： IntStream、LongStream、DoubleStream。当然我们也可以用 Stream、Stream 、Stream，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。 Java 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。 清单 5. 数值流的构造IntStream.of(new int[]{1, 2, 3}).forEach(System.out::println); IntStream.range(1, 3).forEach(System.out::println); IntStream.rangeClosed(1, 3).forEach(System.out::println); 清单 6. 流转换为其它数据结构// 1. Array String[] strArray1 = stream.toArray(String[]::new); // 2. Collection List &lt; String > list1 = stream.collect(Collectors.toList()); List &lt; String > list2 = stream.collect(Collectors.toCollection(ArrayList::new)); Set set1 = stream.collect(Collectors.toSet()); Stack stack1 = stream.collect(Collectors.toCollection(Stack::new)); // 3. String String str = stream.collect(Collectors.joining()).toString(); 一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。 流的操作接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。 Intermediate： map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、parallel、 sequential、 unordered Terminal： forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、allMatch、 noneMatch、 findFirst、 findAny、 iterator Short-circuiting： anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit 我们下面看一下 Stream 的比较典型用法。 map/flatMap 我们先来看 map。如果你熟悉 scala 这类函数式语言，对这个方法应该很了解，它的作用就是把 input Stream 的每一个元素，映射成output Stream 的另外一个元素。 清单 7. 转换大写List &lt; String > output = wordList.stream(). map(String::toUpperCase). collect(Collectors.toList()); 这段代码把所有的单词转换为大写。 清单 8. 平方数List &lt; Integer > nums = Arrays.asList(1, 2, 3, 4); List &lt; Integer > squareNums = nums.stream(). map(n - > n * n). collect(Collectors.toList()); 这段代码生成一个整数 list 的平方数 {1, 4, 9, 16}。 从上面例子可以看出，map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。还有一些场景，是一对多映射关系的，这时需要flatMap。 清单 9. 一对多Stream &lt; List &lt; Integer >> inputStream = Stream.of( Arrays.asList(1), Arrays.asList(2, 3), Arrays.asList(4, 5, 6) ); Stream &lt; Integer > outputStream = inputStream. flatMap((childList) - > childList.stream()); flatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有List 了，都是直接的数字。 filter filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。 清单 10. 留下偶数Integer[] sixNums = { 1, 2, 3, 4, 5, 6 }; Integer[] evens = Stream.of(sixNums).filter(n - > n % 2 == 0).toArray(Integer[]::new); 经过条件“被 2 整除”的 filter，剩下的数字为 {2, 4, 6}。 清单 11. 把单词挑出来List &lt; String > output = reader.lines(). flatMap(line - > Stream.of(line.split(REGEXP))). filter(word - > word.length() > 0). collect(Collectors.toList()); 这段代码首先把每行的单词用 flatMap 整理到新的 Stream，然后保留长度不为 0 的，就是整篇文章中的全部单词了。 forEach forEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。 清单 12. 打印姓名（forEach 和 pre-java8 的对比）// Java 8 roster.stream() .filter(p - > p.getGender() == Person.Sex.MALE) .forEach(p - > System.out.println(p.getName())); // Pre-Java 8 for (Person p: roster) { if (p.getGender() == Person.Sex.MALE) { System.out.println(p.getName()); } } 对一个人员集合遍历，找出男性并打印姓名。可以看出来，forEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda表达式本身是可以重用的，非常方便。当需要为多核系统优化时，可以parallelStream().forEach()，只是此时原有元素的次序没法保证，并行的情况下将改变串行时操作的行为，此时 forEach本身的实现不需要调整，而 Java8 以前的 for 循环 code 可能需要加入额外的多线程逻辑。 但一般认为，forEach 和常规 for 循环的差异不涉及到性能，它们仅仅是函数式风格与传统 Java 风格的差别。 另外一点需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次terminal 运算。下面的代码是错误的： stream.forEach(element - > doOneThing(element)); stream.forEach(element - > doAnotherThing(element)); 相反，具有相似功能的 intermediate 操作 peek 可以达到上述目的。如下是出现在该 api javadoc 上的一个示例。 清单 13. peek 对每个元素执行操作并返回一个新的 StreamStream.of("one", "two", "three", "four") .filter(e - > e.length() > 3) .peek(e - > System.out.println("Filtered value: " + e)) .map(String::toUpperCase) .peek(e - > System.out.println("Mapped value: " + e)) .collect(Collectors.toList()); forEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。 findFirst 这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。 这里比较重点的是它的返回值类型：Optional。这也是一个模仿 Scala语言中的概念，作为一个容器，它可能含有某值，或者不包含。使用它的目的是尽可能避免 NullPointerException。 清单 14. Optional 的两个用例String strA = " abcd ", strB = null; print(strA); print(""); print(strB); getLength(strA); getLength(""); getLength(strB); public static void print(String text) { // Java 8 Optional.ofNullable(text).ifPresent(System.out::println); // Pre-Java 8 if (text != null) { System.out.println(text); } } public static int getLength(String text) { // Java 8 return Optional.ofNullable(text).map(String::length).orElse(-1); // Pre-Java 8 // return if (text != null) ? text.length() : -1; }; 在更复杂的 if (xx != null) 的情况中，使用 Optional 代码的可读性更好，而且它提供的是编译时检查，能极大的降低 NPE 这种Runtime Exception 对程序的影响，或者迫使程序员更早的在编码阶段处理空值问题，而不是留到运行时再发现和调试。 Stream 中的 findAny、max/min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回OptionalDouble 等等。 reduce 这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如Stream 的 sum 就相当于 Integer sum = integers.reduce(0, (a, b) -&gt; a+b); 或 Integer sum = integers.reduce(0, Integer::sum); 也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。 清单 15. reduce 的用例// 字符串连接，concat = "ABCD" String concat = Stream.of("A", "B", "C", "D").reduce("", String::concat); // 求最小值，minValue = -3.0 double minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min); // 求和，sumValue = 10, 有起始值 int sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum); // 求和，sumValue = 10, 无起始值 sumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get(); // 过滤，字符串连接，concat = "ace" concat = Stream.of("a", "B", "c", "D", "e", "F"). filter(x - > x.compareTo("Z") > 0). reduce("", String::concat); 上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。 limit/skip limit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。 清单 16. limit 和 skip 对运行次数的影响public void testLimitAndSkip() { List &lt; Person > persons = new ArrayList(); for (int i = 1; i &lt;= 10000; i++) { Person person = new Person(i, "name" + i); persons.add(person); } List &lt; String > personList2 = persons.stream(). map(Person::getName).limit(10).skip(3).collect(Collectors.toList()); System.out.println(personList2); } private class Person { public int no; private String name; public Person(int no, String name) { this.no = no; this.name = name; } public String getName() { System.out.println(name); return name; } } 输出结果为： name1 name2 name3 name4 name5 name6 name7 name8 name9 name10 [name4, name5, name6, name7, name8, name9, name10] 这是一个有 10，000 个元素的 Stream，但在 short-circuiting 操作 limit 和 skip 的作用下，管道中 map操作指定的 getName() 方法的执行次数为 limit 所限定的 10 次，而最终返回结果在跳过前 3 个元素后只有后面 7 个返回。 有一种情况是 limit/skip 无法达到 short-circuiting 目的的，就是把它们放在 Stream 的排序操作后，原因跟 sorted这个 intermediate 操作有关：此时系统并不知道 Stream 排序后的次序如何，所以 sorted 中的操作看上去就像完全没有被 limit或者 skip 一样。 清单 17. limit 和 skip 对 sorted 后的运行次数无影响List &lt; Person > persons = new ArrayList(); for (int i = 1; i &lt;= 5; i++) { Person person = new Person(i, "name" + i); persons.add(person); } List &lt; Person > personList2 = persons.stream().sorted((p1, p2) - > p1.getName().compareTo(p2.getName())).limit(2).collect(Collectors.toList()); System.out.println(personList2); 上面的示例对清单 13 做了微调，首先对 5 个元素的 Stream 排序，然后进行 limit 操作。输出结果为： name2 name1 name3 name2 name4 name3 name5 name4 [stream.StreamDW$Person@816f27d, stream.StreamDW$Person@87aac27] 即虽然最后的返回元素数量是 2，但整个管道中的 sorted 表达式执行次数没有像前面例子相应减少。 最后有一点需要注意的是，对一个 parallel 的 Steam 管道来说，如果其元素是有序的，那么 limit操作的成本会比较大，因为它的返回对象必须是前 n 个也有一样次序的元素。取而代之的策略是取消元素间的次序，或者不要用 parallel Stream。 sorted 对 Stream 的排序通过 sorted 进行，它比数组的排序更强之处在于你可以首先对 Stream 进行各类 map、filter、limit、skip甚至 distinct 来减少元素数量后，再排序，这能帮助程序明显缩短执行时间。我们对清单 14 进行优化： 清单 18. 优化：排序前进行 limit 和 skipList &lt; Person > persons = new ArrayList(); for (int i = 1; i &lt;= 5; i++) { Person person = new Person(i, "name" + i); persons.add(person); } List &lt; Person > personList2 = persons.stream().limit(2).sorted((p1, p2) - > p1.getName().compareTo(p2.getName())).collect(Collectors.toList()); System.out.println(personList2); 结果会简单很多： name2 name1 [stream.StreamDW$Person@6ce253f1, stream.StreamDW$Person@53d8d10a] 当然，这种优化是有 business logic 上的局限性的：即不要求排序后再取值。 min/max/distinct min 和 max 的功能也可以通过对 Stream 元素先排序，再 findFirst 来实现，但前者的性能会更好，为 O(n)，而 sorted的成本是 O(n log n)。同时它们作为特殊的 reduce 方法被独立出来也是因为求最大最小值是很常见的操作。 清单 19. 找出最长一行的长度BufferedReader br = new BufferedReader(new FileReader("c:\\SUService.log")); int longest = br.lines(). mapToInt(String::length). max(). getAsInt(); br.close(); System.out.println(longest); 下面的例子则使用 distinct 来找出不重复的单词。 清单 20. 找出全文的单词，转小写，并排序List &lt; String > words = br.lines(). flatMap(line - > Stream.of(line.split(" "))). filter(word - > word.length() > 0). map(String::toLowerCase). distinct(). sorted(). collect(Collectors.toList()); br.close(); System.out.println(words); Match Stream 有三个 match 方法，从语义上说： allMatch：Stream 中全部元素符合传入的 predicate，返回 true anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true 它们都不是要遍历全部元素才能返回结果。例如 allMatch 只要一个元素不满足条件，就 skip 剩下的所有元素，返回 false。对清单 13 中的Person 类稍做修改，加入一个 age 属性和 getAge 方法。 清单 21. 使用 MatchList &lt; Person > persons = new ArrayList(); persons.add(new Person(1, "name" + 1, 10)); persons.add(new Person(2, "name" + 2, 21)); persons.add(new Person(3, "name" + 3, 34)); persons.add(new Person(4, "name" + 4, 6)); persons.add(new Person(5, "name" + 5, 55)); boolean isAllAdult = persons.stream(). allMatch(p - > p.getAge() > 18); System.out.println("All are adult? " + isAllAdult); boolean isThereAnyChild = persons.stream(). anyMatch(p - > p.getAge() &lt; 12); System.out.println("Any child? " + isThereAnyChild); 输出结果： All are adult? false Any child? true 进阶：自己生成流 Stream.generate 通过实现 Supplier 接口，你可以自己来控制流的生成。这种情形通常用于随机数、常量的 Stream，或者需要前后元素间维持着某种状态信息的Stream。把 Supplier 实例传递给 Stream.generate() 生成的 Stream，默认是串行（相对 parallel而言）但无序的（相对 ordered 而言）。由于它是无限的，在管道中，必须利用 limit 之类的操作限制 Stream 大小。 清单 22. 生成 10 个随机整数Random seed = new Random(); Supplier &lt; Integer > random = seed::nextInt; Stream.generate(random).limit(10).forEach(System.out::println); //Another way IntStream.generate(() - > (int)(System.nanoTime() % 100)). limit(10).forEach(System.out::println); Stream.generate() 还接受自己实现的 Supplier。例如在构造海量测试数据的时候，用某种自动的规则给每一个变量赋值；或者依据公式计算Stream 的每个元素值。这些都是维持状态信息的情形。 清单 23. 自实现 SupplierStream.generate(new PersonSupplier()). limit(10). forEach(p - > System.out.println(p.getName() + ", " + p.getAge())); private class PersonSupplier implements Supplier &lt; Person > { private int index = 0; private Random random = new Random(); @Override public Personget() { return new Person(index++, "StormTestUser" + index, random.nextInt(100)); } } 输出结果： StormTestUser1, 9 StormTestUser2, 12 StormTestUser3, 88 StormTestUser4, 51 StormTestUser5, 22 StormTestUser6, 28 StormTestUser7, 81 StormTestUser8, 51 StormTestUser9, 4 StormTestUser10, 76 Stream.iterate iterate 跟 reduce 操作很像，接受一个种子值，和一个 UnaryOperator（例如 f）。然后种子值成为 Stream的第一个元素，f(seed) 为第二个，f(f(seed)) 第三个，以此类推。 清单 24. 生成一个等差数列 Stream.iterate(0, n - > n + 3).limit(10).forEach(x - > System.out.print(x + " ")); 输出结果： 0 3 6 9 12 15 18 21 24 27 与 Stream.generate 相仿，在 iterate 时候管道必须有 limit 这样的操作来限制 Stream 大小。 进阶：用 Collectors 来进行 reduction 操作java.util.stream.Collectors 类的主要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为Collection，把 Stream 元素进行归组。 groupingBy/partitioningBy 清单 25. 按照年龄归组Map &lt; Integer, List &lt; Person >> personGroups = Stream.generate(new PersonSupplier()). limit(100). collect(Collectors.groupingBy(Person::getAge)); Iterator it = personGroups.entrySet().iterator(); while (it.hasNext()) { Map.Entry &lt; Integer, List &lt; Person >> persons = (Map.Entry) it.next(); System.out.println("Age " + persons.getKey() + " = " + persons.getValue().size()); } 上面的 code，首先生成 100 人的信息，然后按照年龄归组，相同年龄的人放到同一个 list 中，可以看到如下的输出： Age 0 = 2 Age 1 = 2 Age 5 = 2 Age 8 = 1 Age 9 = 1 Age 11 = 2 …… 清单 26. 按照未成年人和成年人归组Map &lt; Boolean, List &lt; Person >> children = Stream.generate(new PersonSupplier()). limit(100). collect(Collectors.partitioningBy(p - > p.getAge() &lt; 18)); System.out.println("Children number: " + children.get(true).size()); System.out.println("Adult number: " + children.get(false).size()); 输出结果： Children number: 23 Adult number: 77 在使用条件“年龄小于 18”进行分组后可以看到，不到 18 岁的未成年人是一组，成年人是另外一组。partitioningBy 其实是一种特殊的groupingBy，它依照条件测试的是否两种结果来构造返回的数据结构，get(true) 和 get(false) 能即为全部的元素对象。 结束语总之，Stream 的特性可以归纳为： 不是数据结构 它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。 它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。 所有 Stream 的操作必须以 lambda 表达式为参数 不支持索引访问 你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。 很容易生成数组或者 List 惰性化 很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。 Intermediate 操作永远是惰性化的。 并行能力 当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。 可以是无限的 集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。 var autocjs = new AutocJS({ article: '.markdown-body', //文章的ID选择器名称 isOnlyAnchors: true, selector: 'h1,h2,h3,h4', // 不配置 selector 属性，即使用默认选择器 Default：'h1,h2,h3,h4,h5,h6' title: '库存管理', hasDirectoryInArticle: false, // 是否在正文中显示目录 默认 false hasChapterCodeAtHeadings: false, // 是否在 文章标题中显示该标题的段落索引编号 默认 false hasChapterCodeInDirectory: true //是否在导航菜单中显示段落索引编号 默认 true }).show(); // 流程图 var options = {theme: 'hand'}; $(".uml-flowchart").sequenceDiagram(options); $('.gifs').gifplayer(); var show = new Egg("right", function() { autocjs.show(); }).listen(); var hide = new Egg("left", function() { autocjs.hide(); }).listen();]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序列化相关]]></title>
    <url>%2F2018%2F02%2F10%2Fxu-lie-hua-xiang-guan%2F</url>
    <content type="text"><![CDATA[使用序列化类的私有方法巧妙解决部分属性持久化问题 业务场景 一个计税系统和人力资源系统（HR系统）通过RMI（Remote Method Invocation，远程方法调用）对接，计税系统需要从HR系统获得人员的姓名和基本工资，以作为纳税的依据，而HR系统的工资分为两部分：基本工资和绩效工资，基本工资没什么秘密，根据工作岗位和年限自己都可以计算出来，但绩效工资却是保密的，不能泄露到外系统 方案(1) transient关键字 在bonus前加上transient关键字,这是一个方法，但不是一个好方法，加上transient关键字就标志着Salary类失去了分布式部署的功能，它可是HR系统最核心的类了，一旦遭遇性能瓶颈，想再实现分布式部署就不可能了，此方案否定。 方案(2) 新增业务对象 增加一个Person4Tax类，完全为计税系统服务，就是说它只有两个属性：姓名和基本工资。符合开闭原则，而且对原系统也没有侵入性，只是增加了工作量而已。这是个方法，但不是最优方法。方案(3) 请求端过滤 在计税系统获得Person对象后，过滤掉Salary的bonus属性，方案可行但不合规矩，因为HR系统中的Salary类安全性竟然让外系统（计税系统）来承担，设计严重失职。方案(4) 变更传输契约 例如改用XML传输，或者重建一个Web Service服务。可以做，但成本太高。 优秀方案 实现了Serializable接口的类可以实现两个私有方法：writeObject和readObject，以影响和控制序列化和反序列化的过程。 如下 public class Salary implements Serializable { private static final long serialVersionUID = -2140234769839131214L; // 脚本工资 private Double basePay; // 绩效工资 private Double bonus; public Salary(Double basePay, Double bonus) { this.basePay = basePay; this.bonus = bonus; } // 省略 get set 方法 } public class People implements Serializable { private static final long serialVersionUID = -2092465505451534820L; //姓名 private String name; // 绩效 private Salary salary; public People(String name, Salary salary) { this.name = name; this.salary = salary; } //序列化委托方法 private void writeObject(java.io.ObjectOutputStream out) throws IOException { out.defaultWriteObject(); out.writeDouble(salary.getBasePay()); } // 反序列化委托方法 private void readObject(java.io.ObjectInputStream in) throws IOException,ClassNotFoundException { in.defaultReadObject(); salary = new Salary(new Double(0),in.readDouble()); } } public static void main(String[] args) { Salary salary = new Salary(new Double(4000),new Double(5000)); People people = new People("zhangsan", salary); System.out.println(JSONObject.toJSONString(people)); byte[] data = SerializationUtils.serialize(people); People result = (People)SerializationUtils.deserialize(data); System.out.println(JSONObject.toJSONString(result)); } 打印结果{“name”:”zhangsan”,”salary”:{“basePay”:4000.0,”bonus”:5000.0}}{“name”:”zhangsan”,”salary”:{“basePay”:0.0,”bonus”:4000.0}} 使用序列化实现对象的拷贝 业务场景 如果一个项目中有大量的对象是通过拷贝生成的，那我们该如何处理？每个类都写一个clone方法，并且还要深拷贝？想想看这是何等巨大的工作量呀，是否有更好的方法呢？ 其实，可以通过序列化方式来处理，在内存中通过字节流的拷贝来实现，也就是把母对象写到一个字节流中，再从字节流中将其读出来，这样就可以重建一个新对象了，该新对象与母对象之间不存在引用共享的问题，也就相当于深拷贝了一个新对象，代码如下： public class CloneUtils { @SuppressWarnings("unchecked") public static T clone(T obj) { T cloneObj = null; try { // 读取对象字节数据 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(obj); oos.close(); // 分配内存 写入原始对象 生成新对象 ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); cloneObj= (T)ois.readObject(); ois.close(); } catch (Exception ex) { ex.printStackTrace(); } return cloneObj; } } 此工具类要求被拷贝的对象必须实现Serializable接口，否则是没办法拷贝的（当然，使用反射那是另外一种技巧） 用此方法需要注意两点: 对象的内部属性都是可序列化的 如果有内部属性不可序列化，则会抛出序列化异常，这会让调试者很纳闷：生成一个对象怎么会出现序列化异常呢？从这一点来考虑，也需要把CloneUtils工具的异常进行细化处理。 注意方法和属性的特殊修饰符 比如final、static变量的序列化问题会被引入到对象拷贝中来（参考第1章），这点需要特别注意，同时transient变量（瞬态变量，不进行序列化的变量）也会影响到拷贝的效果。 当然，采用序列化方式拷贝时还有一个更简单的办法，即使用Apache下的commons工具包中的SerializationUtils类，直接使用更加简洁方便。 边界 边界 还是边界 @Test public void 边界测试() { Integer intMaxNum= 2147483647; intMaxNum += 1; int limit = 10; // 超过边界 判断失效 if(intMaxNum < limit) { System.out.println("数字"+intMaxNum+"小于" + limit); } } 输出结果数字-2147483648小于10 莫让四舍五入亏了一方 四舍五入。四舍五入是一种近似精确的计算方法，在Java5之前，我们一般是通过使用Math.round来获得指定精度的整数或小数的，这种方法使用非常广泛，代码如下： public static void main (String[] args) { System.out.println("10.5近似值：" + Math.round(10.5)); System.out.println("-10.5近似值：" + Math.round(-10.5)); } 输出结果10.5近似值：11-10.5近似值：-10 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是四舍五入的经典案例，也是初级面试官很乐意选择的考题，绝对值相同的两个数字，近似值为什么就不同了呢？这是由Math.round采用的舍入规则所决定的（采用的是正无穷方向舍入规则，后面会讲解）。我们知道四舍五入是有误差的：其误差值是舍入位的一半。我们以舍入运用最频繁的银行利息计算为例来阐述该问题。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们知道银行的盈利渠道主要是利息差，从储户手里收拢资金，然后放贷出去，其间的利息差额便是所获得的利润。对一个银行来说，对付给储户的利息的计算非常频繁，人民银行规定每个季度末月的20日为银行结息日，一年有4次的结息日。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;场景介绍完毕，我们回过头来看四舍五入，小于5的数字被舍去，大于等于5的数字进位后舍去，由于所有位上的数字都是自然计算出来的，按照概率计算可知，被舍入的数字均匀分布在0到9之间，下面以10笔存款利息计算作为模型，以银行家的身份来思考这个算法： 四舍。舍弃的数值：0.000、0.001、0.002、0.003、0.004，因为是舍弃的，对银行家来说，就不用付款给储户了，那每舍弃一个数字就会赚取相应的金额：0.000、0.001、0.002、0.003、0.004。 五入。进位的数值：0.005、0.006、0.007、0.008、0.009，因为是进位，对银行家来说，每进一位就会多付款给储户，也就是亏损了，那亏损部分就是其对应的10进制补数：0.005、0.004、0.003、0.002、0.001。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为舍弃和进位的数字是在0到9之间均匀分布的，所以对于银行家来说，每10笔存款的利息因采用四舍五入而获得的盈利是：0.000+0.001+0.002+0.003+0.004-0.005-0.004-0.003-0.002-0.001=-0.005 也就是说，每10笔的利息计算中就损失0.005元，即每笔利息计算损失0.0005元，这对一家有5千万储户的银行来说（对国内的银行来说，5千万是个很小的数字），每年仅仅因为四舍五入的误差而损失的金额是： public static void main (String[] args) { //银行账户数量，5千万 int accountNum =5000*10000; //按照人行的规定，每个季度末月的20日为银行结息日 double cost=0.0005*accountNum*4; System.out.println("银行每年损失的金额："+cost); } 输出结果银行每年损失的金额：100000.0 &nbsp;&nbsp;&nbsp;&nbsp;即，每年因为一个算法误差就损失了10万元，事实上以上的假设条件都是非常保守的，实际情况可能损失得更多。那各位可能要说了，银行还要放贷呀，放出去这笔计算误差不就抵消掉了吗？不会抵销，银行的贷款数量是非常有限的，其数量级根本没有办法和存款相比。这个算法误差是由美国银行家发现的（那可是私人银行，钱是自己的，白白损失了可不行），并且对此提出了一个修正算法，叫做银行家舍入（Banker’s Round）的近似算法，其规则如下： 舍去位的数值小于5时，直接舍去； 舍去位的数值大于等于6时，进位后舍去； 当舍去位的数值等于5时，分两种情况：5后面还有其他数字（非0），则进位后舍去；若5后面是0（即5是最后一个数字），则根据5前一位数的奇偶性来判断是否需要进位，奇数进位，偶数舍去。 以上规则汇总成一句话： 四舍六入五考虑，五后非零就进一，五后为零看奇偶，五前为偶应舍去，五前为奇要进一。 我们举例说明，取2位精度： round(10.5551)=10.56 round(10.555)=10.56 round(10.545)=10.54 要在Java5以上的版本中使用银行家的舍入法则非常简单，直接使用RoundingMode类提供的Round模式即可，示例代码如下： public static void main (String[] args) { //存款 BigDecimal d=new BigDecimal(888888); //月利率，乘3计算季利率 BigDecimal r=new BigDecimal(0.001875*3); //计算利息 BigDecimal i=d.multiply(r).setScale(2,RoundingMode.HALF_EVEN); System.out.println("季利息是："+i); } 输出结果季利息是：4999.99 在上面的例子中，我们使用了BigDecimal类，并且采用setScale方法设置了精度，同时传递了一个RoundingMode.HALF_EVEN参数表示使用银行家舍入法则进行近似计算，BigDecimal和RoundingMode是一个绝配，想要采用什么舍入模式使用RoundingMode设置即可。目前Java支持以下七种舍入方式： ROUND_UP：远离零方向舍入。向远离0的方向舍入，也就是说，向绝对值最大的方向舍入，只要舍弃位非0即进位。 ROUND_DOWN：趋向零方向舍入。向0方向靠拢，也就是说，向绝对值最小的方向输入，注意：所有的位都舍弃，不存在进位情况。 ROUND_CEILING：向正无穷方向舍入。向正最大方向靠拢，如果是正数，舍入行为类似于ROUND_UP；如果为负数，则舍入行为类似于ROUND_DOWN。注意：Math.round方法使用的即为此模式。 ROUND_FLOOR：向负无穷方向舍入。向负无穷方向靠拢，如果是正数，则舍入行为类似于ROUND_DOWN；如果是负数，则舍入行为类似于ROUND_UP。 HALF_UP：最近数字舍入（5进）。这就是我们最最经典的四舍五入模式。 HALF_DOWN：最近数字舍入（5舍）。在四舍五入中，5是进位的，而在HALF_DOWN中却是舍弃不进位。 HALF_EVEN：银行家算法。在普通的项目中舍入模式不会有太多影响，可以直接使用Math.round方法，但在大量与货币数字交互的项目中，一定要选择好近似的计算模式，尽量减少因算法不同而造成的损失。]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
</search>
